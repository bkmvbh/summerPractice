//
//  CameraFile.swift
//  summerPractice
//
//  Created by –ò–ª—å–º–∏—Ä –®–∞—Ä–∞—Ñ—É—Ç–¥–∏–Ω–æ–≤ on 24.07.2025.
//

import SwiftUI
import AVFoundation
import MediaPipeTasksVision
import SwiftUI

struct CameraView: View {
    @StateObject private var model = CameraModel()
    @Environment(\.dismiss) var dismiss
    
    var body: some View {
        ZStack {
            // –ü—Ä–µ–≤—å—é –∫–∞–º–µ—Ä—ã
            CameraPreview(session: model.session)
                .ignoresSafeArea()
            
            // –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
            VStack {
                HStack {
                    Spacer()
                    Button(action: { dismiss() }) {
                        Image(systemName: "xmark.circle.fill")
                            .font(.largeTitle)
                            .foregroundColor(.white)
                            .padding()
                    }
                }
                Spacer()
                
                // –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∂–µ—Å—Ç–∞
                Text(model.gesture)
                    .font(.system(size: 60, weight: .bold))
                    .padding()
                    .background(Color.black.opacity(0.5))
                    .cornerRadius(10)
            }
        }
        .onAppear { model.startSession() }
        .onDisappear { model.stopSession() }
        .alert("–û—à–∏–±–∫–∞", isPresented: .constant(model.lastError != nil)) {
            Button("OK") { model.lastError = nil }
        } message: {
            Text(model.lastError?.localizedDescription ?? "")
        }
    }
}

struct CameraPreview: UIViewRepresentable {
    let session: AVCaptureSession
    
    func makeUIView(context: Context) -> UIView {
        let view = UIView(frame: UIScreen.main.bounds)
        let previewLayer = AVCaptureVideoPreviewLayer(session: session)
        previewLayer.videoGravity = .resizeAspectFill
        previewLayer.frame = view.bounds
        view.layer.addSublayer(previewLayer)
        return view
    }
    
    func updateUIView(_ uiView: UIView, context: Context) {
        if let layer = uiView.layer.sublayers?.first as? AVCaptureVideoPreviewLayer {
            layer.frame = uiView.bounds
        }
    }
}

import AVFoundation
import MediaPipeTasksVision

final class CameraModel: NSObject, ObservableObject, AVCaptureVideoDataOutputSampleBufferDelegate {
    
    // MARK: - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    private let sessionQueue = DispatchQueue(label: "camera.session.queue")
    private let mediaPipeQueue = DispatchQueue(label: "mediapipe.processing.queue")
    
    // MARK: - –°–≤–æ–π—Å—Ç–≤–∞
    @Published var gesture: String = ""
    @Published var lastError: Error?
    
    let session = AVCaptureSession()
    private let videoOutput = AVCaptureVideoDataOutput()
    private var handLandmarker: HandLandmarker?
    private var landmarkerDelegate: HandLandmarkerDelegate?
    
    // MARK: - –ñ–∏–∑–Ω–µ–Ω–Ω—ã–π —Ü–∏–∫–ª
    override init() {
        super.init()
        setupCamera()
        setupMediaPipe()
    }
    
    // MARK: - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞–º–µ—Ä—ã
    private func setupCamera() {
        sessionQueue.async {
            do {
                try self.configureCaptureSession()
            } catch {
                self.handleError(error)
            }
        }
    }
    
    private func configureCaptureSession() throws {
        session.beginConfiguration()
        defer { session.commitConfiguration() }
        
        // 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        guard let device = AVCaptureDevice.default(.builtInWideAngleCamera,
                                                 for: .video,
                                                 position: .front) else {
            throw CameraError.deviceUnavailable
        }
        
        // 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        try device.lockForConfiguration()
        if device.isFocusModeSupported(.continuousAutoFocus) {
            device.focusMode = .continuousAutoFocus
        }
        device.unlockForConfiguration()
        
        // 3. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—Ö–æ–¥–∞
        let input = try AVCaptureDeviceInput(device: device)
        guard session.canAddInput(input) else { throw CameraError.inputConfigurationFailed }
        session.addInput(input)
        
        // 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—ã—Ö–æ–¥–∞
        videoOutput.videoSettings = [
            kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
        ]
        videoOutput.alwaysDiscardsLateVideoFrames = true
        guard session.canAddOutput(videoOutput) else { throw CameraError.outputConfigurationFailed }
        session.addOutput(videoOutput)
        videoOutput.setSampleBufferDelegate(self, queue: sessionQueue)
        
        // 5. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        if let connection = videoOutput.connection(with: .video) {
            connection.videoOrientation = .portrait
            if connection.isVideoMirroringSupported {
                connection.isVideoMirrored = true
            }
        }
    }
    
    // MARK: - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MediaPipe
    private func setupMediaPipe() {
        mediaPipeQueue.async {
            do {
                try self.configureHandLandmarker()
                print("‚úÖ MediaPipe —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            } catch {
                self.handleError(error)
            }
        }
    }
    
    private func configureHandLandmarker() throws {
        // 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏
        guard let modelPath = Bundle.main.path(forResource: "hand_landmarker", ofType: "task") else {
            throw CameraError.modelNotFound
        }
        
        // 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–ø—Ü–∏–π
        let options = try HandLandmarkerOptions()
        options.baseOptions.modelAssetPath = modelPath
        options.runningMode = .liveStream
        options.numHands = 1
        options.minHandDetectionConfidence = 0.7
        options.minTrackingConfidence = 0.5
        
        // 3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–µ–ª–µ–≥–∞—Ç–∞
        self.landmarkerDelegate = HandLandmarkerDelegate(model: self)
        options.handLandmarkerLiveStreamDelegate = landmarkerDelegate
        
        // 4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.handLandmarker = try HandLandmarker(options: options)
    }
    
    // MARK: - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–µ–π
    func startSession() {
        sessionQueue.async {
            guard !self.session.isRunning else { return }
            self.session.startRunning()
        }
    }
    
    func stopSession() {
        sessionQueue.async {
            guard self.session.isRunning else { return }
            self.session.stopRunning()
        }
    }
    
    // MARK: - –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤
    func captureOutput(_ output: AVCaptureOutput,
                     didOutput sampleBuffer: CMSampleBuffer,
                     from connection: AVCaptureConnection) {
        mediaPipeQueue.async {
            self.processFrame(sampleBuffer: sampleBuffer)
        }
    }
    
    private func processFrame(sampleBuffer: CMSampleBuffer) {
        // 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        guard self.handLandmarker != nil else {
            DispatchQueue.main.async {
                self.gesture = "MediaPipe –Ω–µ –≥–æ—Ç–æ–≤"
            }
            return
        }
        
        // 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else {
            DispatchQueue.main.async {
                self.gesture = "–û—à–∏–±–∫–∞ –≤–∏–¥–µ–æ–±—É—Ñ–µ—Ä–∞"
            }
            return
        }
        
        // 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞
        do {
            let image = try MPImage(pixelBuffer: pixelBuffer, orientation: .up)
            let timestampMs = Int(Date().timeIntervalSince1970 * 1000)
            
            try self.handLandmarker?.detectAsync(image: image, timestampInMilliseconds: timestampMs)
        } catch {
            self.handleError(error)
        }
    }
    
    // MARK: - –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    func processHandLandmarks(_ result: HandLandmarkerResult) {
        DispatchQueue.main.async {
            guard let landmarks = result.landmarks.first else {
                self.gesture = "‚úã –†—É–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                return
            }
            
            self.detectGestures(from: landmarks)
        }
    }
    
    private func detectGestures(from landmarks: [NormalizedLandmark]) {
        // 1. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–æ—á–∫–∏
        let thumbTip = landmarks[4]
        let indexTip = landmarks[8]
        let middleTip = landmarks[12]
        let ringTip = landmarks[16]
        let pinkyTip = landmarks[20]
        
        // 2. –ñ–µ—Å—Ç "–ö—É–ª–∞–∫" üëä
        let thumbIndexDistance = hypot(thumbTip.x - indexTip.x, thumbTip.y - indexTip.y)
        if thumbIndexDistance < 0.05 {
            self.gesture = "üëä –ö—É–ª–∞–∫"
            return
        }
        
        // 3. –ñ–µ—Å—Ç "–≤–∏–∫—Ç–æ—Ä–∏" ‚úåÔ∏è
        if indexTip.y < middleTip.y && middleTip.y < ringTip.y && middleTip.y < pinkyTip.y {
            self.gesture = "‚úåÔ∏è –í–∏–∫—Ç–æ—Ä–∏"
            return
        }
        
        // 4. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –æ—Ç–∫—Ä—ã—Ç–∞—è –ª–∞–¥–æ–Ω—å
        self.gesture = "üñêÔ∏è –õ–∞–¥–æ–Ω—å"
    }
    
    // MARK: - –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
    private func handleError(_ error: Error) {
        DispatchQueue.main.async {
            self.lastError = error
            print("‚ùå –û—à–∏–±–∫–∞: \(error.localizedDescription)")
        }
    }
    
    // MARK: - –í–ª–æ–∂–µ–Ω–Ω—ã–µ —Ç–∏–ø—ã
    private class HandLandmarkerDelegate: NSObject, HandLandmarkerLiveStreamDelegate {
        weak var model: CameraModel?
        
        init(model: CameraModel) {
            self.model = model
        }
        
        func handLandmarker(_ handLandmarker: HandLandmarker,
                          didFinishDetection result: HandLandmarkerResult?,
                          timestampInMilliseconds: Int,
                          error: Error?) {
            if let error = error {
                self.model?.handleError(error)
                return
            }
            
            guard let result = result else {
                self.model?.handleError(CameraError.noResults)
                return
            }
            
            self.model?.processHandLandmarks(result)
        }
    }
    
    enum CameraError: Error, LocalizedError {
        case deviceUnavailable
        case inputConfigurationFailed
        case outputConfigurationFailed
        case modelNotFound
        case noResults
        case permissionDenied
        
        var errorDescription: String? {
            switch self {
            case .deviceUnavailable: return "–ö–∞–º–µ—Ä–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"
            case .inputConfigurationFailed: return "–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—Ö–æ–¥–∞"
            case .outputConfigurationFailed: return "–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—ã—Ö–æ–¥–∞"
            case .modelNotFound: return "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
            case .noResults: return "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"
            case .permissionDenied: return "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–º–µ—Ä–µ"
            }
        }
    }
}
